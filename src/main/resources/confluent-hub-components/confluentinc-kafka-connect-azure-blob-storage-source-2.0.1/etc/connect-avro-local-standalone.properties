# Sample configuration for a standalone Kafka Connect worker that uses Avro serialization and
# integrates the the SchemaConfig Registry. This sample configuration assumes a local installation of
# Confluent Platform with all services running on their default ports, and is also set up
# to be used by developers of this plugin.

# Bootstrap Kafka servers. If multiple servers are specified, they should be comma-separated.
bootstrap.servers=pkc-lq8gm.westeurope.azure.confluent.cloud:9092
# The converters specify the format of data in Kafka and how to translate it into Connect data.
# Every Connect user will need to configure these based on the format they want their data in
# when loaded from or stored into Kafka
key.converter=org.apache.kafka.connect.storage.StringConverter
key.converter.schema.registry.url=https://psrc-0j199.westeurope.azure.confluent.cloud
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.schema.registry.url=https://psrc-0j199.westeurope.azure.confluent.cloud

# Local storage file for offset data
offset.storage.file.filename=/tmp/connect.offsets
ssl.endpoint.identification.algorithm=https
security.protocol=SASL_SSL
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="U5OY7D3DEZHLRLSK" password="pWP6wZKmJOducnaK1VbKCZk9nn";

# Confuent Control Center Integration -- uncomment these lines to enable Kafka client interceptors
# that will report audit data that can be displayed and analyzed in Confluent Control Center
# producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
# consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor

# Load our plugin from the directory where a local Maven build creates the plugin archive
plugin.path=target/components/packages
